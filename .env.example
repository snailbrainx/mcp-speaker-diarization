# HuggingFace token for accessing pyannote models
# Get your token from: https://huggingface.co/settings/tokens
# Accept pyannote terms at: https://huggingface.co/pyannote/speaker-diarization-3.1
HF_TOKEN=your_huggingface_token_here

# Database URL
DATABASE_URL=sqlite:////app/volumes/speakers.db

# Speaker Recognition Settings
# Threshold for speaker similarity matching (0.0-1.0, lower = more strict)
# 0.30 = recommended for normal home usage (good balance of accuracy and matching)
# 0.20 = stricter matching for movie audio with background music/effects
SPEAKER_THRESHOLD=0.30

# Context padding around segments for embedding extraction (seconds)
# 0.15s = optimal for movie audio with background music/effects
CONTEXT_PADDING=0.15

# Filter out common Whisper hallucinations (true/false)
# Set to false if real speech is being filtered (e.g., actual "thank you" phrases)
FILTER_HALLUCINATIONS=true

# Whisper Transcription Model (faster-whisper with CTranslate2)
# Choose model based on your GPU capabilities:
# - tiny.en / tiny: ~400MB VRAM, fastest, lowest accuracy
# - base.en / base: ~500MB VRAM, very fast, basic accuracy
# - small.en / small: ~1GB VRAM, fast, good accuracy
# - medium.en / medium: ~2GB VRAM, slower, better accuracy
# - large-v3 / large-v2: ~3-4GB VRAM, slowest, best accuracy (recommended for production)
# Use .en models for English-only (slightly faster)
WHISPER_MODEL=large-v3

# Whisper Language Setting
# - "en" = English only (default, fastest)
# - "auto" = Auto-detect language (supports 99 languages)
# - Or specify: "es" (Spanish), "fr" (French), "de" (German), "zh" (Chinese), "ja" (Japanese), etc.
WHISPER_LANGUAGE=en

# Live Recording Settings
# Silence duration before processing segment (seconds)
# Lower = more responsive, but may cut off speech. Higher = more complete segments.
SILENCE_DURATION=0.5
